---
title: "ten_out_of_ten"
output: html_document
date: "2025-03-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
``` 

## External data

```{r}
# Table of contents -------------------------------------------------------
# 1. vdemdata CHECK
# 2. Rainbowmap CHECK
# 3. Economist Democracy Scores for 2018 CHECK
# 4. Happiness CHECK
# 5. GDP per capita CHECK
# 6. ESS round 9 CHECK
# 7. Unemployment rate CHECK
# 8. Gender equality index CHECK  


## further ideas:
# which political parties governed in the years before (i.e., left, centre-right etc.)
# Gini index
# migrant acceptance scores
# welfare state/ size of government relative to GDP
# physical/ mental health issues; quality and equity of healthcare
# solidarity with minority groups
# education


# load libraries ----------------------------------------------------------
# devtools::install_github("vdeminstitute/vdemdata")

library(tidyverse)
library(dplyr)
library(readr)
library(readxl)
library(vdemdata)
library(survey) 
library(countrycode)
library(rvest)
library(stringr)
library(mice)       
library(VIM)
library(visdat)    
library(naniar)     
library(caret)      

# mapping -----------------------------------------------------------------
# we comment out the country codes as we likely don't need them
survey_country_mapping <- data.frame(
  country_name = c("France", "Belgium", "Netherlands", "Germany", "Italy", 
                   "Luxembourg", "Denmark", "Ireland", "United Kingdom", "Greece", 
                   "Spain", "Portugal", "Finland", "Sweden", 
                   "Austria", "Cyprus", "Czech Republic", "Estonia", "Hungary", 
                   "Latvia", "Lithuania", "Malta", "Poland", "Slovakia", 
                   "Slovenia", "Bulgaria", "Romania", "Croatia"),
  #survey_country_code = c(1, 2, 3, 4, 5, 
  #                        6, 7, 8, 9, 11, 
  #                        12, 13, 16, 17, 
  #                        18, 19, 20, 21, 22, 
  #                        23, 24, 25, 26, 27, 
  #                        28, 29, 30, 32),
  iso2 = c("FR", "BE", "NL", "DE", "IT", 
           "LU", "DK", "IE", "GB", "GR", 
           "ES", "PT", "FI", "SE", 
           "AT", "CY", "CZ", "EE", "HU", 
           "LV", "LT", "MT", "PL", "SK", 
           "SI", "BG", "RO", "HR"),
  stringsAsFactors = FALSE)

# create a mapping for country name standardization: the Czech Republic is a problem
country_name_mapping <- c("Czechia" = "Czech Republic")


# 1. vdemdata ----------------------------------------------------------------
# install the package from GitHub first:
# devtools::install_github("vdeminstitute/vdemdata")
vdem_data <- vdem

# apply country name standardization before filtering
vdem_data_standardized <- vdem_data %>%
  mutate(
    # Standardize country names
    country_name = ifelse(country_name %in% names(country_name_mapping),
                          country_name_mapping[country_name],
                          country_name))

# filter for most recent data (2019 to match survey data)
vdem_2019 <- vdem_data_standardized %>%
  filter(country_name %in% survey_country_mapping$country_name, year == 2019) %>%
  select(country_name, v2x_libdem, v2x_polyarchy, v2x_gender, 
         v2x_egaldem, v2x_liberal, v2xcs_ccsi, v2x_freexp)  # select relevant variables

saveRDS(vdem_2019, file = "vdem_eu_2019.rds")
write.csv(vdem_2019, "vdem_eu_2019.csv")

## from the codebook: 
# v2x_libdem: index of liberal democracy
# v2x_polyarchy: index of electoral democracy
# v2x_gender: index of women's political empowerment
# v2x_egaldem: index of egalitarian democracy   
# v2x_liberal: index of civil liberties
# v2xcs_ccsi:  index of civil society participation
# v2x_freexp: index of freedom of expression



# 2. Rainbowmap --------------------------------------------------------------
# https://rainbowmap.ilga-europe.org/

# rainbow_data <- read_csv("data/raw/2024-rainbow-map-data.csv")

# but the problem: that's for 2024, not 2019 or before 2019
# hence, we would need to get the data for 2019 and years before:

# create data frames for each year
df_2019 <- data.frame(
  Country = c("Malta", "Belgium", "United Kingdom", "Norway", "France", "Finland",
              "Denmark", "Spain", "Portugal", "Sweden", "Netherlands", "Austria",
              "Germany", "Croatia", "Greece", "Ireland", "Hungary", "Luxembourg",
              "Iceland", "Slovenia", "Montenegro", "Estonia", "Switzerland", "Georgia",
              "Bosnia & Herzegovina", "Slovakia", "Albania", "Serbia", "Bulgaria", 
              "Czechia", "Kosovo", "Andorra", "Cyprus", "Romania", "Ukraine", 
              "Lithuania", "Italy", "Poland", "Latvia", "Belarus", "Moldova", 
              "Russia", "North Macedonia", "Liechtenstein", "San Marino", "Armenia",
              "Turkey", "Monaco", "Azerbaijan"),
  Value = c(74.72, 70.40, 67.62, 63.64, 62.73, 62.20, 60.31, 58.49, 57.50, 52.86,
            49.72, 48.54, 47.45, 45.83, 44.82, 44.72, 42.83, 41.34, 40.20, 39.82, 
            37.16, 34.38, 30.06, 29.49, 29.37, 29.04, 27.74, 26.43, 25.75, 25.50,
            25.34, 23.93, 22.03, 20.67, 19.97, 19.91, 19.43, 18.10, 16.83, 15.82,
            15.10, 11.75, 10.88, 10.08, 9.87, 8.50, 8.50, 7.31, 5.67),
  Year = 2019)

df_2018 <- data.frame(
  Country = c("Malta", "Belgium", "United Kingdom", "Finland", "France", "Norway",
              "Portugal", "Denmark", "Spain", "Sweden", "Netherlands", "Germany",
              "Austria", "Greece", "Ireland", "Croatia", "Slovenia", "Luxembourg",
              "Iceland", "Hungary", "Estonia", "Switzerland", "Montenegro", "Andorra",
              "Albania", "Kosovo", "Bosnia & Herzegovina", "Serbia", "Czechia", 
              "Cyprus", "Slovakia", "Italy", "Georgia", "Bulgaria", "Lithuania",
              "Romania", "Ukraine", "Poland", "Liechtenstein", "Latvia", 
              "North Macedonia", "Belarus", "Moldova", "San Marino", "Russia", 
              "Monaco", "Turkey", "Armenia", "Azerbaijan"),
  Value = c(91.94, 78.70, 73.48, 73.27, 72.81, 72.74, 69.16, 67.69, 67.03, 60.10,
            59.64, 59.00, 56.40, 52.32, 52.22, 50.58, 47.73, 47.48, 47.22, 47.16,
            39.34, 38.44, 37.74, 34.81, 33.24, 32.98, 31.38, 29.68, 29.20, 28.95,
            28.65, 28.82, 25.87, 24.15, 21.78, 21.12, 20.95, 18.23, 17.87, 16.07,
            14.03, 13.35, 13.08, 12.32, 10.80, 9.78, 8.60, 7.20, 4.70),
  Year = 2018)

df_2017 <- data.frame(
  Country = c("Malta", "Norway", "United Kingdom", "Belgium", "France", "Portugal",
              "Finland", "Denmark", "Spain", "Netherlands", "Croatia", "Sweden", 
              "Austria", "Germany", "Ireland", "Iceland", "Greece", "Luxembourg", 
              "Hungary", "Slovenia", "Montenegro", "Andorra", "Estonia", "Albania",
              "Bosnia & Herzegovina", "Switzerland", "Kosovo", "Serbia", "Czechia", 
              "Cyprus", "Slovakia", "Italy", "Georgia", "Bulgaria", "Romania", 
              "Ukraine", "Poland", "Liechtenstein", "Lithuania", "Latvia", 
              "North Macedonia", "Belarus", "Moldova", "San Marino", "Monaco", 
              "Turkey", "Armenia", "Azerbaijan"),
  Value = c(77.74, 75.73, 71.86, 70.82, 69.16, 68.27, 67.69, 67.03, 64.44, 62.36,
            60.10, 55.58, 54.41, 52.22, 47.22, 46.92, 46.48, 44.82, 44.28, 38.64, 
            34.81, 33.31, 33.24, 31.34, 30.94, 30.48, 29.68, 29.20, 28.95, 27.60, 
            26.67, 25.87, 23.15, 21.12, 19.00, 18.23, 17.87, 17.28, 17.12, 16.03, 
            13.35, 13.08, 12.32, 9.78, 8.60, 7.20, 6.40, 4.70),
  Year = 2017)

df_2016 <- data.frame(
  Country = c("Malta", "Belgium", "United Kingdom", "Spain", "Denmark", "Portugal",
              "Finland", "France", "Croatia", "Netherlands", "Norway", "Sweden", 
              "Austria", "Iceland", "Greece", "Germany", "Ireland", "Hungary", 
              "Luxembourg", "Montenegro", "Estonia", "Albania", "Switzerland", 
              "Andorra", "Serbia", "Cyprus", "Slovenia", "Czechia", "Kosovo", 
              "Georgia", "Bosnia & Herzegovina", "Slovakia", "Bulgaria", "Romania",
              "Italy", "Poland", "Liechtenstein", "Lithuania", "Latvia", 
              "North Macedonia", "San Marino", "Moldova", "Belarus", "Monaco", 
              "Turkey", "Armenia", "Azerbaijan"),
  Value = c(77.75, 81.85, 79.19, 70.95, 70.90, 69.55, 67.25, 66.60, 66.55, 66.10, 
            65.15, 64.85, 62.21, 59.00, 58.30, 55.14, 54.70, 51.40, 50.35, 45.20, 
            38.25, 34.40, 33.15, 32.10, 32.00, 31.95, 31.65, 31.60, 31.55, 30.35, 
            29.40, 29.20, 24.00, 23.45, 19.75, 18.30, 18.20, 18.10, 17.35, 15.55, 
            14.40, 14.15, 13.35, 10.80, 8.75, 7.20, 4.85),
  Year = 2016)

df_2015 <- data.frame(
  Country = c("United Kingdom", "Belgium", "Malta", "Sweden", "Croatia", "Netherlands",
              "Norway", "Spain", "Denmark", "Portugal", "France", "Iceland", "Finland", 
              "Germany", "Austria", "Hungary", "Montenegro", "Luxembourg", "Albania",
              "Ireland", "Greece", "Georgia", "Czechia", "Estonia", "Slovenia",
              "Andorra", "Bosnia & Herzegovina", "Serbia", "Slovakia", "Romania",
              "Switzerland", "Bulgaria", "Poland", "Italy", "Liechtenstein", 
              "Lithuania", "Cyprus", "Kosovo", "Latvia", "Moldova", "Belarus",
              "San Marino", "North Macedonia", "Turkey", "Monaco", "Armenia", 
              "Azerbaijan"),
  Value = c(88.00, 83.00, 77.00, 72.00, 71.00, 69.00, 69.00, 69.00, 68.00, 67.00,
            65.00, 63.00, 62.00, 56.00, 52.00, 50.00, 46.00, 43.00, 42.00, 40.00,
            39.00, 36.00, 35.00, 34.00, 32.00, 31.00, 29.00, 29.00, 29.00, 28.00, 
            28.00, 27.00, 26.00, 22.00, 19.00, 19.00, 18.00, 18.00, 18.00, 16.00,
            14.00, 14.00, 13.00, 12.00, 11.00, 9.00, 5.00),
  Year = 2015)

df_2014 <- data.frame(
  Country = c("United Kingdom", "Belgium", "Spain", "Netherlands", "Norway", 
              "Portugal", "Sweden", "France", "Iceland", "Denmark", "Malta", 
              "Croatia", "Germany", "Hungary", "Austria", "Montenegro", "Finland",
              "Albania", "Slovenia", "Czechia", "Estonia", "Ireland", "Greece", 
              "Slovakia", "Serbia", "Bulgaria", "Switzerland", "Luxembourg", 
              "Romania", "Poland", "Italy", "Georgia", "Lithuania", "Andorra",
              "Bosnia & Herzegovina", "Cyprus", "Latvia", "Liechtenstein", "Kosovo",
              "Moldova", "Turkey", "San Marino", "Belarus", "North Macedonia", 
              "Ukraine", "Monaco", "Armenia", "Azerbaijan"),
  Value = c(80.25, 78.10, 73.26, 69.90, 68.40, 66.60, 65.30, 64.10, 63.95, 59.90,
            56.80, 56.30, 55.68, 53.65, 52.10, 47.05, 45.30, 38.40, 35.00, 34.65, 
            34.65, 33.65, 31.15, 30.50, 30.30, 30.00, 28.85, 28.35, 27.95, 27.65, 
            27.40, 28.05, 21.70, 20.60, 20.10, 19.65, 19.65, 18.00, 17.10, 16.50,
            14.15, 13.70, 13.60, 13.30, 11.65, 10.10, 8.50, 6.60),
  Year = 2014)

df_2013 <- data.frame(
  Country = c("United Kingdom", "Belgium", "Norway", "Sweden", "Spain", "Portugal", 
              "France", "Netherlands", "Denmark", "Iceland", "Hungary", "Germany",
              "Croatia", "Finland", "Austria", "Albania", "Malta", "Slovenia", 
              "Czechia", "Ireland", "Romania", "Estonia", "Switzerland", "Luxembourg",
              "Greece", "Slovakia", "Montenegro", "Serbia", "Poland", "Georgia",
              "Lithuania", "Andorra", "Bosnia & Herzegovina", "Cyprus", "Latvia", 
              "Italy", "Bulgaria", "Liechtenstein", "Turkey", "San Marino", "Belarus",
              "Kosovo", "North Macedonia", "Ukraine", "Monaco", "Armenia", "Azerbaijan"),
  Value = c(78.50, 68.73, 65.65, 65.30, 65.04, 64.60, 64.10, 60.00, 59.80, 55.50,
            54.70, 54.29, 48.30, 47.25, 43.35, 38.40, 35.30, 35.00, 34.65, 33.65, 
            31.30, 28.90, 28.85, 28.35, 28.10, 28.90, 28.65, 25.05, 21.65, 21.05, 
            20.70, 20.60, 19.95, 19.65, 19.65, 19.40, 18.00, 15.50, 14.15, 13.70, 
            13.60, 13.50, 13.30, 11.65, 10.10, 7.50, 7.10),
  Year = 2013)

# combine all data frames into one
df_combined <- bind_rows(df_2019, df_2018, df_2017, df_2016, df_2015, df_2014, df_2013)

# create new, compressed df
# step 1: Filter data for 2019 and 2018
df_2019 <- df_combined %>% filter(Year == 2019) %>% rename(Value_2019 = Value)
df_2018 <- df_combined %>% filter(Year == 2018) %>% rename(Value_2018 = Value)

# step 2: Filter data for 2013 and 2014 and calculate the average
df_2013_2014 <- df_combined %>% filter(Year %in% c(2013, 2014)) %>%
  group_by(Country) %>%
  summarise(Avg_2013_2014 = mean(Value, na.rm = TRUE))

# step 3: Join the data frames for 2019 and 2018
df_compressed <- df_2019 %>%
  left_join(df_2018, by = "Country") %>%
  select(Country, Value_2019, Value_2018)

# step 4: Calculate the average for 2019 and 2018
df_compressed <- df_compressed %>%
  mutate(Avg_2019_2018 = (Value_2019 + Value_2018) / 2)

# step 5: Join the average for 2013 and 2014
df_compressed <- df_compressed %>%
  left_join(df_2013_2014, by = "Country")

# step 6: Calculate the difference between the averages
df_compressed <- df_compressed %>%
  mutate(Difference = Avg_2019_2018 - Avg_2013_2014)

# step 7: Select and reorder columns for the final compressed data frame
df_compressed <- df_compressed %>%
  select(Country, Value_2019, Value_2018, Avg_2019_2018, 
         Avg_2013_2014, Difference)

rainbow_df <- df_compressed

# save the data frame
saveRDS(rainbow_df, file = "rainbow_df.rds")
write.csv(rainbow_df, "rainbow_df.csv")



# 3. The Economist: Democracy scores 2018 ---------------------------------
# https://enperspectiva.uy/wp-content/uploads/2019/01/Democracy_Index_2018.pdf
democracy_scores <- data.frame(
  Country = c("Belgium", "Denmark", "Greece", "Spain", "Finland", "France", "Ireland", "Italy", "Luxembourg", "Netherlands", "Austria", "Portugal", "Sweden", "Germany", "United Kingdom", "Bulgaria", "Cyprus", "Czech Republic", "Estonia", "Hungary", "Latvia", "Lithuania", "Malta", "Poland", "Romania", "Slovakia", "Slovenia", "Croatia"),
  ISO2 = c("BE", "DK", "GR", "ES", "FI", "FR", "IE", "IT", "LU", "NL", "AT", "PT", "SE", "DE", "GB", "BG", "CY", "CZ", "EE", "HU", "LV", "LT", "MT", "PL", "RO", "SK", "SI", "HR"),
  Overall_score = c(7.78, 9.22, 7.29, 8.08, 9.14, 7.80, 9.15, 7.71, 8.81, 8.89, 8.29, 7.84, 9.39, 8.68, 8.53, 7.03, 7.59, 7.69, 7.97, 6.63, 7.38, 7.50, 8.21, 6.67, 6.38, 7.10, 7.50, 6.57),
  #Global_rank = c(31, 5, 39, 19, 8, 29, "6=", 33, 12, 11, 16, 27, 3, 13, 14, 46, 35, 34, "23=", "57=", 38, "36=", 18, "54=", "66=", 44, "36=", 60),
  #Regional_rank = c(17, 4, 20, 14, 6, 16, 5, 18, 9, 8, 12, 15, 3, 10, 11, 7, 19, 2, 1, 9, 5, "3=", 13, 8, 12, 6, "3=", 10),
  Electoral_process_and_pluralism = c(9.58, 10.00, 9.58, 9.17, 10.00, 9.58, 9.58, 9.58, 10.00, 9.58, 9.58, 9.58, 9.58, 9.58, 9.58, 9.17, 9.17, 9.58, 9.58, 8.75, 9.58, 9.58, 9.17, 9.17, 9.17, 9.58, 9.58, 9.17),
  Functioning_of_government = c(8.93, 9.29, 5.36, 7.14, 8.93, 7.50, 7.86, 6.07, 8.93, 9.29, 7.86, 7.50, 9.64, 8.57, 7.50, 6.43, 6.43, 6.79, 8.21, 6.07, 6.07, 6.43, 8.21, 6.07, 5.71, 6.79, 6.79, 6.07),
  Political_participation = c(5.00, 8.33, 6.11, 7.78, 8.33, 7.78, 8.33, 7.78, 6.67, 8.33, 8.33, 6.11, 8.33, 8.33, 8.33, 7.22, 6.67, 6.67, 6.67, 5.00, 5.56, 6.11, 6.11, 6.11, 5.00, 5.56, 6.67, 5.56),
  Political_culture = c(6.88, 9.38, 6.88, 7.50, 8.75, 5.63, 10.00, 6.88, 8.75, 8.13, 6.88, 6.88, 10.00, 7.50, 8.13, 4.38, 6.88, 6.88, 6.88, 6.25, 6.88, 6.25, 8.75, 4.38, 4.38, 5.63, 6.25, 5.00),
  Civil_liberties = c(8.53, 9.12, 8.53, 8.82, 9.71, 8.53, 10.00, 8.24, 9.71, 9.12, 8.82, 9.12, 9.41, 9.41, 9.12, 7.94, 8.82, 8.53, 8.53, 7.06, 8.82, 9.12, 8.82, 7.65, 7.65, 7.94, 8.24, 7.06),
  Regime_type = c("Flawed democracy", "Full democracy", "Flawed democracy", "Full democracy", "Full democracy", "Flawed democracy", "Full democracy", "Flawed democracy", "Full democracy", "Full democracy", "Full democracy", "Flawed democracy", "Full democracy", "Full democracy", "Full democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy", "Full democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy", "Flawed democracy"))

saveRDS(democracy_scores, file = "democracy_scores.rds")
write.csv(democracy_scores, "democracy_scores.csv")


# 4. Happiness data 2018 ---------------------------------------------------------------------
# https://s3.amazonaws.com/happiness-report/2018/WHR_web.pdf
happiness_scores <- data.frame(
  Country = c("Finland", "Denmark", "Greece", "Spain", "France", "Ireland", "Italy", "Luxembourg", "Netherlands", "Austria", "Portugal", "Sweden", "Germany", "United Kingdom", "Bulgaria", "Cyprus", "Czech Republic", "Estonia", "Hungary", "Latvia", "Lithuania", "Malta", "Poland", "Romania", "Slovakia", "Slovenia", "Croatia"),
  ISO2 = c("FI", "DK", "GR", "ES", "FR", "IE", "IT", "LU", "NL", "AT", "PT", "SE", "DE", "GB", "BG", "CY", "CZ", "EE", "HU", "LV", "LT", "MT", "PL", "RO", "SK", "SI", "HR"),
  Happiness_Score = c(7.632, 7.555, 5.358, 6.310, 6.489, 6.977, 6.000, 6.910, 7.441, 7.139, 5.410, 7.314, 6.965, 6.814, 4.933, 5.762, 6.711, 5.739, 5.620, 5.933, 5.952, 6.627, 6.123, 5.945, 6.173, 5.948, 5.321))

saveRDS(happiness_scores, file = "happiness_scores.rds")
write.csv(happiness_scores, "happiness_scores.csv")


# 5. GDP per capita ---------------------------------------------------------------------
df_GDP <- read_csv("data/raw/data_20250228194704.csv")

# apply the mapping to the CountryName column
df_GDP <- df_GDP %>%
  mutate(
    # replace Czechia with Czech Republic
    CountryName = ifelse(CountryName %in% names(country_name_mapping), 
                         country_name_mapping[CountryName], 
                         CountryName)) %>%
  select("CountryName", "PeriodCode", "Value") %>%
  # now filter after standardizing the names
  filter(CountryName %in% survey_country_mapping$country_name)

df_GDP <- df_GDP %>%
  mutate(Value = as.numeric(as.character(Value)))

df_GDP <- df_GDP %>%
  # group by country
  group_by(CountryName) %>% 
  # find first and last year values
  summarize(
    gdp_2005 = Value[PeriodCode == 2005],
    gdp_2018 = Value[PeriodCode == 2018],
    # calculate relative growth
    gdp_growth = (gdp_2018 - gdp_2005) / gdp_2005 * 100) %>%
  # add ISO2 codes for easier joining with other datasets
  left_join(survey_country_mapping, by = c("CountryName" = "country_name")) %>%
  # select relevant columns
  select(CountryName, iso2, gdp_2005, gdp_2018, gdp_growth)

saveRDS(df_GDP, file = "df_GDP.rds")
write.csv(df_GDP, "df_GDP.csv")


# 6. ESS Round 9 ----------------------------------------------------------
# https://ess.sikt.no/en/datafile/b2b0bf39-176b-4eca-8d26-3c05ea83d2cb
ess_data <- read_csv("data/raw/ESS9e03_2.csv")

# select interesting variables, country and weight variables
ess_selected <- ess_data %>%
  select(
    # identifiers and weights
    cntry,          # country code
    pspwght,        # post-stratification weight
    dweight,        # design weight
    
    # key variables of interest
    freehms,        # gays and lesbians free to live life as they wish
    lrscale,        # left-right political scale
    rlgdgr,         # how religious are you
    ipeqopt,        # important that people are treated equally
    atchctr,        # attachment to country
    eduyrs,         # years of education
    agea)            # age of respondent

# function to recode ESS special values (negative values are typically missing values)
recode_ess_missing <- function(x) {
  ifelse(x < 0, NA, x)
}

# clean the data
ess_clean <- ess_selected %>%
  # recode special values to NA
  mutate(across(c(freehms, lrscale, rlgdgr, ipeqopt, atchctr, eduyrs, agea), 
                recode_ess_missing)) %>%
  # create derived variables if needed
  mutate(
    # recode freehms to 0-1 scale (originally 1-5 where 1 = agree strongly)
    freehms_support = case_when(
      freehms %in% c(1, 2) ~ 1,  # agree and strongly agree
      freehms %in% c(3, 4, 5) ~ 0,  # neutral, disagree, strongly disagree
      TRUE ~ NA_real_),
    
    # create age groups
    age_group = case_when(
      agea < 35 ~ "18-34",
      agea < 55 ~ "35-54",
      TRUE ~ "55+"
    ),
    
    # standardise left-right scale to 0-1
    lrscale_std = (lrscale - 1) / 9,  # Original scale is 1-10
    
    # create high education indicator (above country median)
    high_educ = NA  # will fill this in after calculating country medians
  )

# calculate country median education for relative education measure
country_medians <- ess_clean %>%
  group_by(cntry) %>%
  summarize(median_educ = median(eduyrs, na.rm = TRUE))

# join back to main data and create high education indicator
ess_clean <- ess_clean %>%
  left_join(country_medians, by = "cntry") %>%
  mutate(high_educ = ifelse(eduyrs > median_educ, 1, 0))

# calculate weighted means by country
country_aggregates <- ess_clean %>%
  # group by country
  group_by(cntry) %>%
  # calculate weighted statistics
  summarize(
    # sample size
    n_respondents = n(),
    n_valid = sum(!is.na(freehms)),
    
    # weighted means
    pct_lgbt_support = weighted.mean(freehms_support, w = pspwght, na.rm = TRUE) * 100,
    mean_religiosity = weighted.mean(rlgdgr, w = pspwght, na.rm = TRUE),
    mean_left_right = weighted.mean(lrscale_std, w = pspwght, na.rm = TRUE),
    mean_equal_values = weighted.mean(ipeqopt, w = pspwght, na.rm = TRUE),
    mean_country_attach = weighted.mean(atchctr, w = pspwght, na.rm = TRUE),
    mean_eduyrs = weighted.mean(eduyrs, w = pspwght, na.rm = TRUE),
    mean_age = weighted.mean(agea, w = pspwght, na.rm = TRUE),
    
    # weighted proportions for categorical variables
    pct_young = weighted.mean(age_group == "18-34", w = pspwght, na.rm = TRUE) * 100,
    pct_high_educ = weighted.mean(high_educ, w = pspwght, na.rm = TRUE) * 100,
    
    # standard errors (for confidence intervals)
    se_lgbt_support = sd(freehms_support, na.rm = TRUE) / sqrt(sum(!is.na(freehms_support))),
    
    # missing data proportions
    pct_missing_lgbt = mean(is.na(freehms)) * 100)

# calculate cross-variable country indicators
country_indicators <- ess_clean %>%
  group_by(cntry) %>%
  summarize(
    # correlation between age and LGBT support within country
    age_lgbt_corr = cor(agea, freehms_support, use = "pairwise.complete.obs", method = "spearman"),
    
    # correlation between religiosity and LGBT support
    relig_lgbt_corr = cor(rlgdgr, freehms_support, use = "pairwise.complete.obs", method = "spearman"),
    
    # inequality in LGBT support (standard deviation)
    lgbt_support_inequality = sd(freehms_support, na.rm = TRUE),
    
    # education gradient in LGBT support (difference between high and low education)
    educ_gradient = weighted.mean(freehms_support[high_educ == 1], w = pspwght[high_educ == 1], na.rm = TRUE) - 
      weighted.mean(freehms_support[high_educ == 0], w = pspwght[high_educ == 0], na.rm = TRUE))

# join the aggregates and indicators
country_data_final <- country_aggregates %>%
  left_join(country_indicators, by = "cntry") %>%
  # create ISO country codes for easier merging with other datasets
  mutate(
    iso2c = countrycode(cntry, "iso2c", "iso2c"),
    iso3c = countrycode(cntry, "iso2c", "iso3c"))

# plot LGBT support by country
ggplot(country_data_final, aes(x = reorder(cntry, pct_lgbt_support), y = pct_lgbt_support)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_errorbar(aes(ymin = pct_lgbt_support - 1.96*se_lgbt_support, 
                    ymax = pct_lgbt_support + 1.96*se_lgbt_support), 
                width = 0.2) +
  labs(title = "Support for LGBT Rights by Country",
       subtitle = "Percent agreeing gays and lesbians should be free to live as they wish",
       x = "Country",
       y = "Support (%)") +
  theme_minimal() +
  coord_flip()

# examine relationship between religiosity and LGBT support
ggplot(country_data_final, aes(x = mean_religiosity, y = pct_lgbt_support, label = cntry)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_text(hjust = -0.3, vjust = 0.3) +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(title = "Religiosity vs. LGBT Support by Country",
       x = "Mean Religiosity Score",
       y = "LGBT Support (%)") +
  theme_minimal()

saveRDS(country_data_final, file = "country_data_final.rds")
write.csv(country_data_final, "country_data_final.csv")



# 7. Unemployment rate ----------------------------------------------------
# https://en.wikipedia.org/wiki/List_of_European_Union_member_states_by_unemployment_rate

# scrape data from Wikipedia
url <- "https://en.wikipedia.org/wiki/List_of_European_Union_member_states_by_unemployment_rate"
page <- read_html(url)
tables <- html_table(page, fill = TRUE)
eu_unemployment_table <- tables[[1]]

# clean column names - simplify them to more standard names
colnames(eu_unemployment_table) <- c("Country", "Unemployment", "Employment", "Year")

# clean up the country names by removing footnote references
eu_unemployment_table$Country <- gsub("\\[.*?\\]", "", eu_unemployment_table$Country)

# make sure numeric columns are properly formatted
eu_unemployment_table$Unemployment <- as.character(eu_unemployment_table$Unemployment)
eu_unemployment_table$Employment <- as.numeric(as.character(eu_unemployment_table$Employment))
eu_unemployment_table$Year <- as.numeric(as.character(eu_unemployment_table$Year))

eu_unemployment_table <- eu_unemployment_table %>%
  mutate(
    # trim spaces from country names
    Country = trimws(Country),
    # convert Unemployment to numeric (remove any % signs or spaces if present)
    Unemployment = as.numeric(gsub("[^0-9.]", "", Unemployment)))

# modify Greece's unemployment rate to the 2018 value
eu_unemployment_table$Unemployment[eu_unemployment_table$Country == "Greece"] <- 19.18
eu_unemployment_table$Year[eu_unemployment_table$Country == "Greece"] <- 2018

# add the UK data manually
uk_data <- data.frame(
  Country = "United Kingdom",
  Unemployment = 4.12, # from Statista
  Employment = 75.25,  # estimated from https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/articles/singlemonthlabourforcesurveyestimates/december2018
  Year = 2018)

# append UK data to the table
eu_unemployment_table <- rbind(eu_unemployment_table, uk_data)

# ignore the year column
eu_unemployment_table <- eu_unemployment_table %>%
  select(-Year)

# save
saveRDS(eu_unemployment_table, file = "eu_unemployment_table.rds")
write.csv(eu_unemployment_table, "eu_unemployment_table.csv", row.names = FALSE)


# 8. Gender equality ------------------------------------------------------
# https://eige.europa.eu/gender-statistics/dgs/indicator/index__index_scores/datatable?time=2017&col=domain&row=geo
gender_eq_index <- read_xlsx("data/raw/index__index_scores.xlsx", range = "A16:V44")

gender_eq_index <- gender_eq_index %>%
  select(country_name = "Geographic region\\(Sub-) Domain Scores", 
         gender_equality_index = "Overall Gender Equality Index") %>%
  mutate(country_name = ifelse(country_name == "Czechia", "Czech Republic", country_name))

# Merge the data ----------------------------------------------------------
# create a base dataframe with country identifying variables
country_level_df <- survey_country_mapping

# merge V-Dem data
country_level_df <- country_level_df %>%
  left_join(vdem_2019, by = c("country_name" = "country_name"))

# fix country name in democracy_scores for Czech Republic if needed
if(any(democracy_scores$Country == "Czechia")) {
  democracy_scores$Country[democracy_scores$Country == "Czechia"] <- "Czech Republic"
}

# merge democracy scores
country_level_df <- country_level_df %>%
  left_join(democracy_scores, by = c("iso2" = "ISO2"))

# merge GDP data
country_level_df <- country_level_df %>%
  left_join(df_GDP, by = "iso2")

# rename some countries to match our country_name format
rainbow_country_mapping <- data.frame(
  original = c("Czechia", "Andorra", "Bosnia & Herzegovina", "North Macedonia", "United Kingdom"),
  standardized = c("Czech Republic", "Andorra", "Bosnia and Herzegovina", "Macedonia", "United Kingdom"),
  stringsAsFactors = FALSE)

# apply standardized country names
for(i in 1:nrow(rainbow_country_mapping)) {
  rainbow_df$Country[rainbow_df$Country == rainbow_country_mapping$original[i]] <- 
    rainbow_country_mapping$standardized[i]
}

# extract and rename rainbow map variables for clarity
rainbow_data_clean <- rainbow_df %>%
  select(
    Country,
    rainbow_score_2019 = Value_2019,
    rainbow_score_2018 = Value_2018,
    rainbow_score_avg_2019_2018 = Avg_2019_2018,
    rainbow_score_avg_2013_2014 = Avg_2013_2014,
    rainbow_score_difference = Difference)

# merge Rainbow Map data
country_level_df <- country_level_df %>%
  left_join(rainbow_data_clean, by = c("country_name" = "Country"))

# merge happiness data
country_level_df <- country_level_df %>%
  left_join(happiness_scores, by = c("iso2" = "ISO2"))

# merge unemployment data
country_level_df <- country_level_df %>%
  left_join(eu_unemployment_table, by = c("country_name" = "Country"))

# create a mapping between ESS country codes and ISO2
ess_country_mapping <- data.frame(
  cntry = c("AT", "BE", "BG", "HR", "CY", "CZ", "DK", "EE", "FI", "FR", 
            "DE", "HU", "IE", "IT", "LV", "LT", "NL", "PL", "PT", "RO", 
            "SK", "SI", "ES", "SE", "GB"),
  iso2 = c("AT", "BE", "BG", "HR", "CY", "CZ", "DK", "EE", "FI", "FR", 
           "DE", "HU", "IE", "IT", "LV", "LT", "NL", "PL", "PT", "RO", 
           "SK", "SI", "ES", "SE", "GB"),
  stringsAsFactors = FALSE)

# first ensure cntry codes match our iso2 codes
country_data_final <- country_data_final %>%
  left_join(ess_country_mapping, by = "cntry") %>%
  select(-iso2c, -iso3c) # remove original ISO codes to avoid confusion

# rename variables for clarity
ess_data_clean <- country_data_final %>%
  select(
    cntry,
    n_respondents,
    n_valid,
    lgbt_support_percent = pct_lgbt_support,
    mean_religiosity,
    mean_left_right,
    mean_equal_values,
    mean_country_attach,
    mean_eduyrs,
    mean_age,
    pct_young,
    pct_high_educ,
    se_lgbt_support,
    pct_missing_lgbt,
    age_lgbt_corr,
    relig_lgbt_corr,
    lgbt_support_inequality,
    educ_gradient,
    #iso3c
  )

# merge ESS data
country_level_df <- country_level_df %>%
  left_join(ess_data_clean, by = c("iso2" = "cntry"))

country_level_df %>% View()

# delete the first Greece row
greece_rows <- which(country_level_df$country_name == "Greece")

if (length(greece_rows) > 1) {
  # remove the first instance of Greece
  country_level_df <- country_level_df[-greece_rows[1], ]
  
  # verify the fix worked
  greece_check <- country_level_df %>%
    filter(country_name == "Greece")
  print("Greece entries after removing the first instance:")
  print(greece_check)
}

# add the gender equality index
country_level_df <- country_level_df %>%
  left_join(gender_eq_index, by = "country_name")

## scaling: necessary for the regression analysis later on because the variables have vastly different scales
country_level_df %>% 
  select(where(is.numeric)) %>% 
  summary()

# we'll apply different scaling methods based on the type of variable:
# 1. z-score standardization: for continuous variables to make them comparable (mean=0, sd=1)
# 2. min-max normalization: for variables with natural bounds (e.g., 0-100 scores)
# 3. log transformation: for heavily skewed variables like GDP

# custom function to standardize (z-score)
standardize <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}

# custom function to min-max normalize
normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

# z-scores for the democracy scores
country_level_df <- country_level_df %>%
  mutate(
    z_v2x_libdem = standardize(v2x_libdem),
    z_v2x_polyarchy = standardize(v2x_polyarchy),
    z_v2x_gender = standardize(v2x_gender),
    z_v2x_egaldem = standardize(v2x_egaldem),
    z_v2x_liberal = standardize(v2x_liberal),
    z_v2xcs_ccsi = standardize(v2xcs_ccsi),
    z_v2x_freexp = standardize(v2x_freexp))

# z-scores for GDP and unemployment rate, natural log for GDP
country_level_df <- country_level_df %>%
  mutate(
    z_gdp_2018 = standardize(gdp_2018),
    log_gdp_2018 = log(gdp_2018),
    z_gdp_growth = standardize(gdp_growth),
    z_unemployment = standardize(Unemployment))

# z-scores and normalised rainbow variables 
country_level_df <- country_level_df %>%
  mutate(
    z_rainbow_score = standardize(rainbow_score_2019),
    norm_rainbow_score = normalize(rainbow_score_2019),
    z_lgbt_support = standardize(lgbt_support_percent),
    norm_lgbt_support = normalize(lgbt_support_percent))

# z-socres and normalised for happiness scores and gender equality
country_level_df <- country_level_df %>%
  mutate(
    z_happiness = standardize(Happiness_Score),
    z_gender_equality = standardize(gender_equality_index),
    norm_gender_equality = normalize(gender_equality_index))

# religion, politics, education and age
country_level_df <- country_level_df %>%
  mutate(
    z_religiosity = standardize(mean_religiosity),
    z_left_right = standardize(mean_left_right),
    z_equal_values = standardize(mean_equal_values),
    z_country_attach = standardize(mean_country_attach),
    z_eduyrs = standardize(mean_eduyrs),
    z_age = standardize(mean_age))

# create two composite scores and regional classification
country_level_df <- country_level_df %>%
  mutate(
    composite_equality = rowMeans(
      cbind(z_gender_equality, z_rainbow_score, z_v2x_gender),
      na.rm = TRUE))

country_level_df <- country_level_df %>%
  mutate(
    composite_democracy = rowMeans(
      cbind(z_v2x_libdem, z_v2x_polyarchy, z_v2x_libdem, z_v2x_freexp), 
      na.rm = TRUE))

country_level_df <- country_level_df %>%
  mutate(
    region = case_when(
      country_name %in% c("Denmark", "Finland", "Sweden", "Estonia", "Latvia", "Lithuania") ~ 
        "Northern Europe",
      country_name %in% c("Belgium", "Netherlands", "Luxembourg", "Germany", "France", 
                          "Austria", "United Kingdom", "Ireland") ~ 
          "Western Europe",
       country_name %in% c("Portugal", "Spain", "Italy", "Malta", "Greece", "Cyprus") ~ 
        "Southern Europe",
      country_name %in% c("Poland", "Czech Republic", "Slovakia", "Hungary", "Slovenia", 
                          "Croatia", "Romania", "Bulgaria") ~           "Eastern Europe",
        TRUE ~ NA_character_))

# delete the "Country.x", "Country.y" and "CountryName" columns
country_level_df <- country_level_df %>%
  select(-c("Country.x", "Country.y", "CountryName"))

# save as RDS and csv
saveRDS(country_level_df, file = "country_level_df.rds")
write.csv(country_level_df, "country_level_df.csv")
```

## Data cleaning

```{r}
### data cleaning

library(tidyverse)
library(sjlabelled)
library(haven)
library(mice)

data <- read_dta("data/raw/ZA7575.dta")

### 
# code the questions properly:
# 'DK' and refusals are especially a problem for questions with ordinal variables, 
# less so for non-ordinal variables; for reasons of completeness, we clean all of
# the 'DK' and refusals (and some other special cases) by converting them to NAs

data_correctly_coded <- data %>%
  mutate(
    # hard cases for me
    d72_1 = ifelse(d72_1 %in% c(5,6), NA, d72_1),
    d72_2 = ifelse(d72_2 %in% c(5,6), NA, d72_2),
    d60 = ifelse(d60 == 7, NA, d60),
    d25 = ifelse(d25 == 8, NA, d25),
    d8 = ifelse(d8 > 70, NA, d8), # subjective decision that no one can have more than 70 years of ed (even full-time professors)
    d7 = ifelse(d7 %in% c(15,97), NA, d7),
    d1 = ifelse(d1 %in% c(97,98), NA, d1),
    
    qa16_1 = ifelse(qa16_1 == 5, NA, qa16_1),
    qa16_2 = ifelse(qa16_2 == 5, NA, qa16_2),
    qa16_3 = ifelse(qa16_3 == 5, NA, qa16_3),
    qa16_4 = ifelse(qa16_4 == 5, NA, qa16_4),
    
    d71_1 = ifelse(d71_1 == 4, NA, d71_1),
    d71_2 = ifelse(d71_2 == 4, NA, d71_2),
    d71_3 = ifelse(d71_3 == 4, NA, d71_3),
    #qb4_1 = ifelse(qb4_1 == 5, NA, qb4_1),
    #qb4_2 = ifelse(qb4_2 == 5, NA, qb4_2),
    #qb4_3 = ifelse(qb4_3 == 5, NA, qb4_3),
    #qb4_4 = ifelse(qb4_4 == 5, NA, qb4_4),
    
    qb3_1 = ifelse(qb3_1 == 5, NA, qb3_1),
    qb3_2 = ifelse(qb3_2 == 5, NA, qb3_2),
    qb3_3 = ifelse(qb3_3 == 5, NA, qb3_3),
    qb3_4 = ifelse(qb3_4 == 5, NA, qb3_4),
    qb3_5 = ifelse(qb3_5 == 5, NA, qb3_5),
    qb3_6 = ifelse(qb3_6 == 5, NA, qb3_6),
    qb3_7 = ifelse(qb3_7 == 5, NA, qb3_7),
    
    qb4_1 = ifelse(qb4_1 == 5, NA, qb4_1),
    qb4_2 = ifelse(qb4_2 == 5, NA, qb4_2),
    qb4_3 = ifelse(qb4_3 == 5, NA, qb4_3),
    qb4_4 = ifelse(qb4_4 == 5, NA, qb4_4),
    qb4_5 = ifelse(qb4_5 == 5, NA, qb4_5),
    
    qb5_1 = ifelse(qb5_1 == 5, NA, qb5_1),
    qb5_2 = ifelse(qb5_2 == 5, NA, qb5_2),
    qb5_3 = ifelse(qb5_3 == 5, NA, qb5_3),
    qb5_4 = ifelse(qb5_4 == 5, NA, qb5_4),
    
    sd1_1 = ifelse(sd1_1 %in% c(3,4), NA, sd1_1),
    sd1_2 = ifelse(sd1_2 %in% c(3,4), NA, sd1_2),
    sd1_3 = ifelse(sd1_3 %in% c(3,4), NA, sd1_3),
    sd1_4 = ifelse(sd1_4 %in% c(3,4), NA, sd1_4),
    sd1_5 = ifelse(sd1_5 %in% c(3,4), NA, sd1_5),
    sd1_6 = ifelse(sd1_6 %in% c(3,4), NA, sd1_6),
    sd1_7 = ifelse(sd1_7 %in% c(3,4), NA, sd1_7),
    sd1_8 = ifelse(sd1_8 %in% c(3,4), NA, sd1_8),
    
    qc1_1 = ifelse(qc1_1 == 6, NA, qc1_1),
    qc1_2 = ifelse(qc1_2 == 6, NA, qc1_2),
    qc1_3 = ifelse(qc1_3 == 6, NA, qc1_3),
    qc1_4 = ifelse(qc1_4 == 6, NA, qc1_4),
    qc1_5 = ifelse(qc1_5 == 6, NA, qc1_5),
    qc1_6 = ifelse(qc1_6 == 6, NA, qc1_6),
    qc1_7 = ifelse(qc1_7 == 6, NA, qc1_7),
    qc1_8 = ifelse(qc1_8 == 6, NA, qc1_8),
    qc1_9 = ifelse(qc1_9 == 6, NA, qc1_9),
    qc1_10 = ifelse(qc1_10 == 6, NA, qc1_10),
    
    qc5_1 = ifelse(qc5_1 == 3, NA, qc5_1),
    qc5_2 = ifelse(qc5_2 == 3, NA, qc5_2),
    qc5_3 = ifelse(qc5_3 == 3, NA, qc5_3),
    qc5_4 = ifelse(qc5_4 == 3, NA, qc5_4),
    
    qc6_1 = ifelse(qc6_1 == 12, NA, qc6_1),
    qc6_2 = ifelse(qc6_2 == 12, NA, qc6_2),
    qc6_3 = ifelse(qc6_3 == 12, NA, qc6_3),
    qc6_4 = ifelse(qc6_4 == 12, NA, qc6_4),
    qc6_5 = ifelse(qc6_5 == 12, NA, qc6_5),
    qc6_6 = ifelse(qc6_6 == 12, NA, qc6_6),
    qc6_7 = ifelse(qc6_7 == 12, NA, qc6_7),
    qc6_8 = ifelse(qc6_8 == 12, NA, qc6_8),
    qc6_9 = ifelse(qc6_9 == 12, NA, qc6_9),
    qc6_10 = ifelse(qc6_10 == 12, NA, qc6_10),
    qc6_11 = ifelse(qc6_11 == 12, NA, qc6_11),
    
    qc9_1 = ifelse(qc9_1 == 7, NA, qc9_1),
    qc9_2 = ifelse(qc9_2 == 7, NA, qc9_2),
    qc9_3 = ifelse(qc9_3 == 7, NA, qc9_3),
    qc9_4 = ifelse(qc9_4 == 7, NA, qc9_4),
    qc9_5 = ifelse(qc9_5 == 7, NA, qc9_5),
    qc9_6 = ifelse(qc9_6 == 7, NA, qc9_6),
    qc9_7 = ifelse(qc9_7 == 7, NA, qc9_7),
    qc9_8 = ifelse(qc9_8 == 7, NA, qc9_8),
    qc9_9 = ifelse(qc9_9 == 7, NA, qc9_9),
    qc9_10 = ifelse(qc9_10 == 7, NA, qc9_10),
    qc9_11 = ifelse(qc9_11 == 7, NA, qc9_11),
    
    qc11_1 = ifelse(qc11_1 == 6, NA, qc11_1),
    qc11_2 = ifelse(qc11_2 == 6, NA, qc11_2),
    qc11_3 = ifelse(qc11_3 == 6, NA, qc11_3),
    qc11_4 = ifelse(qc11_4 == 6, NA, qc11_4),
    qc11_5 = ifelse(qc11_5 == 6, NA, qc11_5),
    qc11_6 = ifelse(qc11_6 == 6, NA, qc11_6),
    
    qc12_1 = ifelse(qc12_1 %in% c(11,12,13), NA, qc12_1),
    qc12_2 = ifelse(qc12_2 %in% c(11,12,13), NA, qc12_2),
    qc12_3 = ifelse(qc12_3 %in% c(11,12,13), NA, qc12_3),
    qc12_4 = ifelse(qc12_4 %in% c(11,12,13), NA, qc12_4),
    qc12_5 = ifelse(qc12_5 %in% c(11,12,13), NA, qc12_5),
    qc12_6 = ifelse(qc12_6 %in% c(11,12,13), NA, qc12_6),
    qc12_7 = ifelse(qc12_7 %in% c(11,12,13), NA, qc12_7),
    qc12_8 = ifelse(qc12_8 %in% c(11,12,13), NA, qc12_8),
    qc12_9 = ifelse(qc12_9 %in% c(11,12,13), NA, qc12_9),
    qc12_10 = ifelse(qc12_10 %in% c(11,12,13), NA, qc12_10),
    qc12_11 = ifelse(qc12_11 %in% c(11,12,13), NA, qc12_11),
    qc12_12 = ifelse(qc12_12 %in% c(11,12,13), NA, qc12_12),
    qc12_13 = ifelse(qc12_13 %in% c(11,12,13), NA, qc12_13),
    qc12_14 = ifelse(qc12_14 %in% c(11,12,13), NA, qc12_14),
    qc12_15 = ifelse(qc12_14 %in% c(11,12,13), NA, qc12_15),
    
    qc13_1 = ifelse(qc13_1 %in% c(11,12,13), NA, qc13_1),
    qc13_2 = ifelse(qc13_2 %in% c(11,12,13), NA, qc13_2),
    qc13_3 = ifelse(qc13_3 %in% c(11,12,13), NA, qc13_3),
    qc13_4 = ifelse(qc13_4 %in% c(11,12,13), NA, qc13_4),
    qc13_5 = ifelse(qc13_5 %in% c(11,12,13), NA, qc13_5),
    qc13_6 = ifelse(qc13_6 %in% c(11,12,13), NA, qc13_6),
    qc13_7 = ifelse(qc13_7 %in% c(11,12,13), NA, qc13_7),
    qc13_8 = ifelse(qc13_8 %in% c(11,12,13), NA, qc13_8),
    qc13_9 = ifelse(qc13_9 %in% c(11,12,13), NA, qc13_9),
    qc13_10 = ifelse(qc13_10 %in% c(11,12,13), NA, qc13_10),
    qc13_11 = ifelse(qc13_11 %in% c(11,12,13), NA, qc13_11),
    qc13_12 = ifelse(qc13_12 %in% c(11,12,13), NA, qc13_12),
    qc13_13 = ifelse(qc13_13 %in% c(11,12,13), NA, qc13_13),
    qc13_14 = ifelse(qc13_14 %in% c(11,12,13), NA, qc13_14),
    qc13_15 = ifelse(qc13_14 %in% c(11,12,13), NA, qc13_15),
    
    qc15_1 = ifelse(qc15_1 == 5, NA, qc15_1),
    qc15_2 = ifelse(qc15_2 == 5, NA, qc15_2),
    qc15_3 = ifelse(qc15_3 == 5, NA, qc15_3),
    
    qc16_1 = ifelse(qc16_1 == 5, NA, qc16_1),
    
    qc17_1 = ifelse(qc17_1 == 5, NA, qc17_1),
    qc17_2 = ifelse(qc17_2 == 5, NA, qc17_2),
    qc17_3 = ifelse(qc17_3 == 5, NA, qc17_3),
    qc17_4 = ifelse(qc17_4 == 5, NA, qc17_4),
    qc17_5 = ifelse(qc17_5 == 5, NA, qc17_5),
    qc17_6 = ifelse(qc17_6 == 5, NA, qc17_6),
    qc17_7 = ifelse(qc17_7 == 5, NA, qc17_7),
    
    qc18_1 = ifelse(qc18_1 %in% c(11,12), NA, qc18_1),
    qc18_2 = ifelse(qc18_2 %in% c(11,12), NA, qc18_2),
    qc18_3 = ifelse(qc18_3 %in% c(11,12), NA, qc18_3),
    
    sd3 = ifelse(sd3 %in% c(15,16), NA, sd3),
    
    # easy cases for Claude
    #q1 = ifelse(q1 %in% c(29,30), NA, q1),
    
    qa1 = ifelse(qa1 == 5, NA, qa1),
    
    qa7 = ifelse(qa7 == 5, NA, qa7),
    
    qa8 = ifelse(qa8 == 4, NA, qa8),
    
    qa9 = ifelse(qa9 == 6, NA, qa9),
    
    qa14 = ifelse(qa14 == 6, NA, qa14),
    
    qa17 = ifelse(qa17 == 5, NA, qa17),
    
    qb6 = ifelse(qb6 == 4, NA, qb6),
    
    qb7 = ifelse(qb7 == 5, NA, qb7),
    
    qc19 = ifelse(qc19 == 3, NA, qc19),
    
    qc20 = ifelse(qc20 == 3, NA, qc20),
    
    d63 = ifelse(d63 %in% c(6,7,8,9), NA, d63), # manually because stupid Claude
    
    d77 = ifelse(d77 == 5, NA, d77),
    
    d70 = ifelse(d70 == 5, NA, d70),
    
    qa4a = ifelse(qa4a %in% c(7,8), NA, qa4a),
    
    qa5a = ifelse(qa5a %in% c(11,12,13), NA, qa5a),
    
    qa11 = ifelse(qa11 %in% c(4,5), NA, qa11),
    
    qa12 = ifelse(qa12 %in% c(5,6), NA, qa12),
    
    qa13 = ifelse(qa13 %in% c(6,7), NA, qa13),
    
    qa18a = ifelse(qa18a %in% c(7,8,9), NA, qa18a),
    
    qb8 = ifelse(qb8 == 5, NA, qb8),
    
    sd3 = ifelse(sd3 == 16, NA, sd3),
    
    qc3 = ifelse(qc3 %in% c(10,11), NA, qc3),
    
    qc7 = ifelse(qc7 %in% c(11,12), NA, qc7),
    
    qc8 = ifelse(qc8 %in% c(11,12), NA, qc8),
    
    qc10 = ifelse(qc10 %in% c(9,10), NA, qc10))

# write_rds(data_correctly_coded, file = "data_correctly_coded.rds")


###
# get rid of all the "r" coded ones
# for the questions with underscores, (1) if they are on a scale, e.g., 1-3 and 'DK'
# is one of them, replace 'DK'; if it's 0-1 coding, keep that (can't do anything about it)

data_correctly_coded <- data_correctly_coded %>%
  select(-matches("_r$|_r[0-9]$|_r[0-9]_")) 
# use setdiff() to check whether it's done properly 


### 
# now analyse the patterns of NAs across columns
missing_data_before <- data_correctly_coded %>%
  summarise(across(everything(), ~sum(is.na(.))/n())) %>%
  pivot_longer(cols = everything(), 
               names_to = "variable", 
               values_to = "missing_proportion") %>%
  arrange(desc(missing_proportion))

# view top variables with missing data
print(head(missing_data_before, 20))

# viz
ggplot(missing_data_before %>% filter(missing_proportion > 0.25), 
       aes(x = reorder(variable, missing_proportion), y = missing_proportion)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Variables with >25% Missing Data",
       x = "Variable",
       y = "Proportion Missing") +
  theme_minimal()

# calculate overall proportion of missing data
mean(missing_data_before$missing_proportion)

# deeper analysis
missing_by_prefix <- missing_data_before %>%
  mutate(prefix = str_extract(variable, "^[a-z]+\\d+")) %>%
  group_by(prefix) %>%
  summarise(
    avg_missing = mean(missing_proportion),
    n_vars = n(),
    max_missing = max(missing_proportion),
    min_missing = min(missing_proportion)
  ) %>%
  arrange(desc(avg_missing))

print(head(missing_by_prefix, 15))

# we take out the following variables because (1) they exhibited high missingness
# while at the same aren't super releveant (that's an assumption we make) for our
# subsequent analysis
data_correctly_coded <- data_correctly_coded %>%
  select(
    # Exclude variables with specific prefixes
    -starts_with("p6"),   # Size of locality
    -starts_with("p7"),   # Region
    -starts_with("p13"),  # Language of interview
    -starts_with("d40"),  # Household size
    -starts_with("qa3"),  # Not benefitting from trade
    -starts_with("qa15"), # Countries bought goods from
    -starts_with("qa2"),  # Benefitting from trade
    -starts_with("qb8"),  # EU energy label influence
    -starts_with("qa18b"), # Information sources follow-up
    -starts_with("qc3")   # Discrimination circumstances
  )

# check how much we imporved the missingness rate
missing_data_after <- data_correctly_coded %>%
  summarise(across(everything(), ~sum(is.na(.))/n())) %>%
  pivot_longer(cols = everything(), 
               names_to = "variable", 
               values_to = "missing_proportion") %>%
  arrange(desc(missing_proportion))

mean(missing_data_after$missing_proportion)

# prepare for imputation
data_correctly_coded <-  data_correctly_coded %>%
  mutate(isocntry = as.factor(isocntry)) %>%
  # remove other problematic variables (like IDs) if needed
  select(!any_of(c("doi", "version", "caseid", "uniqid", "serialid"))) %>%
  sjlabelled::remove_all_labels()

# delete variables with zero variance as they cannot ever be useful predictors
var_zero <- data_correctly_coded %>% 
  select(where(is.numeric)) %>%
  summarise(across(everything(), var, na.rm = TRUE)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "variance") %>%
  filter(variance == 0 | is.na(variance))

if(nrow(var_zero) > 0) {
  cat("Removing", nrow(var_zero), "variables with zero variance\n")
  data_correctly_coded <- data_correctly_coded %>%
    select(!any_of(var_zero$variable))
}

data_correctly_coded <- data_correctly_coded %>%
  # convert country codes: collapse East and West Germany into one DE
  mutate(isocntry = case_when(
    isocntry %in% c("DE-W", "DE-E") ~ "DE",
    TRUE ~ isocntry))

###
# run the imputation
set.seed(1212)

start_time <- Sys.time()
imp_model <- mice(data_correctly_coded, m = 3, method = 'rf', maxit = 3)
end_time <- Sys.time()
end_time - start_time

df_rf_new <- complete(imp_model, action = 3)

# write_rds(df_rf_new, "df_rf_new.rds")

```


## Data cleaning: external datasets

```{r}
## why still z-scores for mean religosity, left-right  etc. 

country_level_df <- readRDS("country_level_df.rds")

# first, let's check which variables have missing values
missing_summary <- colSums(is.na(country_level_df))
missing_summary <- missing_summary[missing_summary > 0]
print(missing_summary)

# Visualize missing data patterns
vis_miss(country_level_df)

# we have the following imputation strategy:
# (1) we will have to delete the variables from the ESS because the Eurobarometer
# survey contains similar information and imputing these values didn't seem appropriate
# (2) we chose to impute the happiness score using KNN

# (1) 
# delete ESS variables
ESS_variables <- c(
  # original survey variables
  "n_respondents", "n_valid", "lgbt_support_percent", "mean_religiosity", 
  "mean_left_right", "mean_equal_values", "mean_country_attach", 
  "mean_eduyrs", "mean_age", "pct_young", "pct_high_educ", "se_lgbt_support",
  
  # additional ESS metrics
  "pct_missing_lgbt", "age_lgbt_corr", "relig_lgbt_corr", 
  "lgbt_support_inequality", "educ_gradient",
  
  # z-score transformations of ESS variables
  "z_religiosity", "z_left_right", "z_equal_values", 
  "z_country_attach", "z_eduyrs", "z_age")

country_level_df <- country_level_df %>%
  select(-all_of(ESS_variables))

# (2)
# create separate datasets for variables that need imputation
missing_variables <- names(missing_summary)[missing_summary < 5 & 
                                             !(names(missing_summary) %in% ESS_variables)]

# for our KNN imputation, we need to identify variables to use as predictors
# these should be variables without NAs that also correlate with those we want to impute

# identify complete variables that could serve as predictors
complete_variables <- names(country_level_df)[colSums(is.na(country_level_df)) == 0]
complete_variables <- complete_variables[!complete_variables %in% c("Unnamed: 0", "country_name", "iso2", "region")]

print(complete_variables)

# custom function to impute variables with KNN, handling non-numeric data
knn_impute <- function(data, vars_to_impute, predictor_vars, k = 5) {
  # create a copy of the data
  imputed_data <- data
  
  # ensure predictor variables are numeric and complete
  pred_data <- data[, predictor_vars, drop = FALSE]
  pred_data <- as.data.frame(lapply(pred_data, function(x) as.numeric(x)))
  
  # remove any non-numeric columns
  numeric_cols <- sapply(pred_data, is.numeric)
  if(any(!numeric_cols)) {
    warning("Removing non-numeric predictor columns: ", 
            paste(names(pred_data)[!numeric_cols], collapse=", "))
    pred_data <- pred_data[, numeric_cols, drop=FALSE]
    predictor_vars <- predictor_vars[numeric_cols]
  }
  
  # handle missing values in predictor variables by using column means
  for(col in names(pred_data)) {
    if(any(is.na(pred_data[[col]]))) {
      pred_data[[col]][is.na(pred_data[[col]])] <- mean(pred_data[[col]], na.rm=TRUE)
    }
  }
  
  # standardize the predictor variables manually to avoid issues
  pred_data_std <- as.data.frame(scale(pred_data))
  
  # for each variable to impute:
  for (var in vars_to_impute) {
    if (var %in% names(data) && sum(is.na(data[[var]])) > 0) {
      # ensure the target variable is numeric
      if (!is.numeric(data[[var]])) {
        cat("Skipping", var, "as it is not numeric\n")
        next
      }
      
      # identify cases with missing values
      missing_indices <- which(is.na(data[[var]]))
      
      # for each missing value:
      for (idx in missing_indices) {
        # calculate Euclidean distances to all other countries
        distances <- numeric(nrow(data))
        
        for (i in 1:nrow(data)) {
          if (i != idx) {
            # calculate squared differences for each predictor
            squared_diffs <- sapply(names(pred_data_std), function(p) {
              (pred_data_std[idx, p] - pred_data_std[i, p])^2
            })
            
            # sum and take square root for Euclidean distance
            distances[i] <- sqrt(sum(squared_diffs, na.rm=TRUE))
          } else {
            distances[i] <- Inf  # don't use the country itself
          }
        }
        
        # find k nearest neighbors with non-missing values for this variable
        valid_neighbors <- which(!is.na(data[[var]]) & !is.infinite(distances))
        
        if (length(valid_neighbors) > 0) {
          # order the neighbors by distance
          neighbor_order <- order(distances[valid_neighbors])
          valid_neighbors <- valid_neighbors[neighbor_order]
          
          # take the k nearest, or as many as available if fewer than k
          k_actual <- min(k, length(valid_neighbors))
          nearest_k <- valid_neighbors[1:k_actual]
          
          # impute as the average of the k nearest neighbors
          imputed_data[idx, var] <- mean(data[nearest_k, var], na.rm = TRUE)
          
          cat("Imputed", var, "for", data$country_name[idx], 
              "using neighbors:", paste(data$country_name[nearest_k], collapse=", "), "\n")
        } else {
          cat("Warning: Could not impute", var, "for", data$country_name[idx], 
              "- no valid neighbors found\n")
        }
      }
    }
  }
  
  return(imputed_data)
}

# now use the function to impute variables with missing values
# first ensure we have the right variable types
country_df_numeric <- country_level_df

for (var in missing_variables) {
  if (var %in% names(country_level_df) && !is.numeric(country_level_df[[var]])) {
    country_df_numeric[[var]] <- as.numeric(as.character(country_level_df[[var]]))
  }
}

# run the imputation with proper error handling
tryCatch({
  country_df_imputed <- knn_impute(
    data = country_df_numeric,
    vars_to_impute = missing_variables,
    predictor_vars = complete_variables,
    k = 3  # using 3 nearest neighbors
  )
  print("Imputation completed successfully!")
}, error = function(e) {
  # if the knn_impute function still fails, let's try an alternative approach
  print(paste("KNN imputation error:", e$message))
  print("Switching to a simpler mean imputation approach...")
  
  country_df_imputed <- country_df_numeric
  for (var in missing_variables) {
    if (sum(is.na(country_df_imputed[[var]])) > 0) {
      # Calculate mean of non-missing values
      var_mean <- mean(country_df_imputed[[var]], na.rm = TRUE)
      # Replace missing values with mean
      country_df_imputed[[var]][is.na(country_df_imputed[[var]])] <- var_mean
      print(paste("Imputed", var, "with mean value:", var_mean))
    }
  }
  return(country_df_imputed)
})

# save
saveRDS(country_df_imputed, file = "country_df_imputed.rds") 
write.csv(country_df_imputed, "country_df_imputed.csv", row.names = FALSE)

```


## Country aggregates

```{r}
# libraries
library(dplyr)
library(tidyr)
library(readr)

# load the data
df_rf_new <- read_csv("df_rf_new.csv") # the imputed dataset
country_df_imputed <- readRDS("country_df_imputed.rds") # external dataset

# custom function to calculate country-level aggregates
calculate_country_aggregates <- function(df) {
  country_agg <- df %>%
    group_by(isocntry) %>%
    summarize(
      
      iso2 = first(isocntry),
      
      # demographics
      mean_age = mean(d11, na.rm = TRUE),
      median_age = median(d11, na.rm = TRUE),
      
      # life satisfaction (recoded)
      mean_life_satisfaction = mean(5 - d70, na.rm = TRUE), 
      pct_satisfied = mean(d70 %in% c(1, 2), na.rm = TRUE) * 100,
      
      # political discussions
      mean_natl_political_discuss = mean(d71_1, na.rm = TRUE),
      mean_eu_political_discuss = mean(d71_2, na.rm = TRUE),
      mean_local_political_discuss = mean(d71_3, na.rm = TRUE),
      pct_discuss_natl_politics = mean(d71_1 %in% c(1, 2), na.rm = TRUE) * 100,
      pct_discuss_eu_politics = mean(d71_2 %in% c(1, 2), na.rm = TRUE) * 100,
      pct_discuss_local_politics = mean(d71_3 %in% c(1, 2), na.rm = TRUE) * 100,
      
      # trade and globalization (recoded)
      mean_trade_support = mean(5 - qa1, na.rm = TRUE),
      pct_trade_support = mean(qa1 %in% c(1, 2), na.rm = TRUE) * 100,
      pct_pro_globalization = mean(qa5a %in% c(1, 2, 3, 5, 7, 8), na.rm = TRUE) * 100,
      pct_anti_globalization = mean(qa5a %in% c(4, 6, 9, 10), na.rm = TRUE) * 100,
      mean_eu_trade_support = mean(5 - qa7, na.rm = TRUE),
      pct_support_eu_trade = mean(qa7 %in% c(1, 2), na.rm = TRUE) * 100,
      mean_esg_support = mean(5 - qa9, na.rm = TRUE),
      pct_support_esg = mean(qa9 %in% c(1, 2), na.rm = TRUE) * 100,
      
      # political and social indicators
      mean_left_right = mean(d1, na.rm = TRUE),
      pct_left = mean(d1 %in% c(1, 2, 3, 4), na.rm = TRUE) * 100,
      pct_center = mean(d1 %in% c(5, 6), na.rm = TRUE) * 100,
      pct_right = mean(d1 %in% c(7, 8, 9, 10), na.rm = TRUE) * 100,
      mean_education_years = mean(d8, na.rm = TRUE),
      median_education_years = median(d8, na.rm = TRUE),
      pct_high_education = mean(d8 >= 20, na.rm = TRUE) * 100,
      pct_rural = mean(d25 == 1, na.rm = TRUE) * 100,
      pct_urban = mean(d25 %in% c(2, 3), na.rm = TRUE) * 100,
      pct_large_urban = mean(d25 == 3, na.rm = TRUE) * 100,
      mean_financial_difficulty = mean(4 - d60, na.rm = TRUE),
      pct_financial_difficulty = mean(d60 %in% c(1, 2), na.rm = TRUE) * 100,
      mean_subjective_class = mean(d63, na.rm = TRUE),
      pct_working_class = mean(d63 == 1, na.rm = TRUE) * 100,
      pct_middle_class = mean(d63 %in% c(2, 3, 4), na.rm = TRUE) * 100,
      pct_upper_class = mean(d63 == 5, na.rm = TRUE) * 100,
      mean_voice_in_eu = mean(5 - d72_1, na.rm = TRUE),
      mean_voice_in_country = mean(5 - d72_2, na.rm = TRUE),
      pct_voice_in_eu = mean(d72_1 %in% c(1, 2), na.rm = TRUE) * 100,
      pct_voice_in_country = mean(d72_2 %in% c(1, 2), na.rm = TRUE) * 100,
      
      # diversity indicators
      pct_friends_diff_ethnic = mean(sd1_1 == 1, na.rm = TRUE) * 100,
      pct_friends_diff_skin = mean(sd1_2 == 1, na.rm = TRUE) * 100,
      pct_friends_roma = mean(sd1_3 == 1, na.rm = TRUE) * 100,
      pct_friends_lgbt = mean(sd1_4 == 1, na.rm = TRUE) * 100,
      pct_friends_disabled = mean(sd1_5 == 1, na.rm = TRUE) * 100,
      pct_friends_diff_religion = mean(sd1_6 == 1, na.rm = TRUE) * 100,
      pct_friends_transgender = mean(sd1_7 == 1, na.rm = TRUE) * 100,
      pct_friends_intersex = mean(sd1_8 == 1, na.rm = TRUE) * 100,
      pct_ethnic_minority = mean(sd2_1 == 1, na.rm = TRUE) * 100,
      pct_skin_minority = mean(sd2_2 == 1, na.rm = TRUE) * 100,
      pct_religious_minority = mean(sd2_3 == 1, na.rm = TRUE) * 100,
      pct_roma = mean(sd2_4 == 1, na.rm = TRUE) * 100,
      pct_sexual_minority = mean(sd2_5 == 1, na.rm = TRUE) * 100,
      pct_disability = mean(sd2_6 == 1, na.rm = TRUE) * 100,
      pct_other_minority = mean(sd2_7 == 1, na.rm = TRUE) * 100,
      pct_any_minority = mean(sd2_1 == 1 | sd2_2 == 1 | sd2_3 == 1 | sd2_4 == 1 | 
                                sd2_5 == 1 | sd2_6 == 1 | sd2_7 == 1, na.rm = TRUE) * 100,
      
      # religion
      pct_catholic = mean(sd3 == 1, na.rm = TRUE) * 100,
      pct_orthodox = mean(sd3 == 2, na.rm = TRUE) * 100,
      pct_protestant = mean(sd3 == 3, na.rm = TRUE) * 100,
      pct_other_christian = mean(sd3 == 4, na.rm = TRUE) * 100,
      pct_jewish = mean(sd3 == 5, na.rm = TRUE) * 100,
      pct_muslim = mean(sd3 %in% c(6, 7, 8), na.rm = TRUE) * 100,
      pct_atheist = mean(sd3 == 13, na.rm = TRUE) * 100,
      pct_nonbeliever = mean(sd3 == 14, na.rm = TRUE) * 100,
      pct_nonreligious = mean(sd3 %in% c(13, 14), na.rm = TRUE) * 100,
      
      # subjective discrimination perception (recoded)
      mean_discrim_ethnic = mean(5 - qc1_1, na.rm = TRUE),
      mean_discrim_skin = mean(5 - qc1_2, na.rm = TRUE),
      mean_discrim_roma = mean(5 - qc1_3, na.rm = TRUE),
      mean_discrim_lgbt = mean(5 - qc1_4, na.rm = TRUE),
      mean_discrim_age = mean(5 - qc1_5, na.rm = TRUE),
      mean_discrim_religion = mean(5 - qc1_6, na.rm = TRUE),
      mean_discrim_disability = mean(5 - qc1_7, na.rm = TRUE),
      mean_discrim_transgender = mean(5 - qc1_8, na.rm = TRUE),
      mean_discrim_gender = mean(5 - qc1_9, na.rm = TRUE),
      mean_discrim_intersex = mean(5 - qc1_10, na.rm = TRUE),
      
    )
  return(country_agg)
}

# apply the function
country_aggregates <- calculate_country_aggregates(df_rf_new)

# join 
country_data_combined <- country_df_imputed %>%
  left_join(country_aggregates, by = "iso2")

# while it's less relevant for a ML model such as random forest, for a multi-level 
# regression model, it's important to standardize the values to allow for better
# coefficient interpretation; the goal is to have both z-scores and 0-1 normalised
# values for each of the original variables (except for variables like 'region')

country_data_combined <- country_data_combined %>%
  # first handle all numeric variables that aren't already standardized
  mutate(
    # z-score standardization
    across(where(is.numeric) & 
             !starts_with("z_") & 
             !starts_with("norm_") &
             !matches("country|iso"), 
           list(z = ~scale(.)[,1]),
           .names = "z_{.col}"),
    
    # also create 0-1 normalized versions
    across(where(is.numeric) & 
             !starts_with("z_") & 
             !starts_with("norm_") &
             !matches("country|iso"), 
           list(norm = ~(.-min(., na.rm=TRUE))/(max(., na.rm=TRUE)-min(., na.rm=TRUE))),
           .names = "norm_{.col}"))

# save the combined dataset
saveRDS(country_data_combined, file = "country_data_combined.rds")
write_csv(country_data_combined, "country_data_combined.csv")

# join with df_rf; the actual, imputed survey data
df_rf_enriched_new <- df_rf_new %>%
  # ISO codes as key
  left_join(country_data_combined, by = c("isocntry" = "iso2"))

# save final dataset
write_csv(df_rf_enriched_new, "df_rf_enriched_new.csv")

```


## 