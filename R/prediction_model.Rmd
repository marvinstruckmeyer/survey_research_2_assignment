---
title: "Prediction Model"
author: "Phong, Marvin, Isabel"
date: "2025-03-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

# Objectives

Machine learning techniques will be applied to forecast support levels <https://github.com/phongtdng/Coursework---Text-Mining>based on observed trends.

Ensure the modelâ€™s accuracy and reliability, rigorous calibration and validation will be necessary.

# Library

```{r}
library(tidyverse)
library(ggplot2)
library(caret)
library(ROSE)
library(corrplot)
library(glmnet)
library(lme4)
```

# Data

```{r}
data <- read_rds("../df_rf_enriched.rds")
```

# Train Model

## Training Data Split

```{r}
set.seed(3147)
trainIndex <- createDataPartition(data$qc19, p=0.7,
                             list = FALSE,
                             times = 1)
train <- data[trainIndex,]
test <- data[-trainIndex,]
```

## Data Imbalance Check

```{r}
train %>% 
  mutate(isocntry = ifelse(isocntry %in% c("DE-W", "DE-E"), "DE", isocntry)) %>% 
  group_by(qc19) %>% 
  summarise(count = n()) %>% 
  mutate(percent = count/sum(count)) %>% 
  arrange(desc(percent)) %>% 
  ungroup() %>% 
  ggplot(aes(x= qc19, y=percent, label=count)) +
  geom_col() +
  geom_text(vjust = -0.3)
```

There is a clear imbalance within the answers to qc19. We, therefore, will balance the data set in order to improve the performance of the prediction model.

## Regularization

### Correlation Check

```{r}
cor <- cor(train %>% select_if(is.numeric))

corrplot(cor, method="color", type="lower", tl.cex = 0.2)
```

### Lasso Dimension Reduction

```{r}
set.seed(5472)
# 10-fold cross-validation to select lambda
lambdas <- 10^seq(-3,5, length.out=100)

# Matrix of predictors
X <- train %>% select(-qc19) %>% as.matrix()
y <- train %>% select(qc19) %>% scale(center=TRUE, scale=FALSE) %>% as.matrix()

# Lasso with Cross-validation
lasso <- cv.glmnet(X,  y, 
                   alpha = 1, lambda = lambdas,
                   standardize = TRUE, nfolds = 10)

# Plot cv results
plot(lasso)
```

```{r}
# Best cv lambda
lambda_cv <- lasso$lambda.min

# Fit final model
model_cv <- glmnet(X, y, alpha = 1, lambda = lambda_cv, standardize = TRUE)
y_hat_cv <- predict(model_cv, X)
ssr_cv <- t(y-y_hat_cv) %*% (y - y_hat_cv)

# Check R-squared
rsq_lasso_cv <- cor(y, y_hat_cv)^2
rsq_lasso_cv
```

```{r}
lasso_coefs <- coef(model_cv)

select_features_lasso <- rownames(lasso_coefs)[coefs[,1] != 0][-1]
select_features_lasso
```

### Elastic Net Dimension Reduction

```{r message = FALSE}
set.seed(3244)
# Training control
ctrl <- trainControl(method = "repeatedcv",
                     number=5,
                     repeats = 5,
                     search = "random",
                     verboseIter = TRUE)
# Train model
enet <- train(qc19 ~., data = train, method="glmnet",
              ppreProcess = c("center", "scale"),
              tuneLength = 15, 
              trControl = ctrl)

# Check R-Squared
y_hat_enet <- predict(enet, select(train, -qc19))
rsq_enet <- cor(y, y_hat_enet)^2
rsq_enet
```

```{r}
# Columns with coef = 0
enet_coefs <- coef(enet$finalModel, enet$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() 

select_features_enet <- enet_coefs %>% 
  filter(s1 != 0) %>% 
  row.names() %>% 
  .[-1]
select_features_enet
```

## Feature Selection

```{r}
train_lasso <- train %>% 
  select(all_of(c(select_features_lasso, "qc19")))

# Mapping enet
select <- c()
for (i in colnames(train %>% select_if(is.character))) {
  if (sum(grepl("isocntry", select_features_enet)) >0) {
    select <- c(select,i)
  }
}

train_enet <- train %>% 
  select(any_of(c(select_features_enet, select, "qc19"))) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(qc19 = as.factor(qc19))
```

## Model Training

```{r}
ctrl <- trainControl(method = "repeatedcv", number=5,
                     repeats = 5, verboseIter = TRUE)
```

### Random Forest (RF)

```{r}
# enet

## under
ctrl$sampling <- "down"
rf_enet_under <- train(
  qc19 ~ .,
  data = train_enet,
  method = "rf",
  trControl = ctrl
)
saveRDS(rf_enet_under, file = "models/rf_enet_under.rds")

## upper
ctrl$sampling <- "up"
rf_enet_upper <- train(
  qc19 ~ .,
  data = train_enet,
  method = "rf",
  trControl = ctrl
)
saveRDS(rf_enet_upper, file = "models/rf_enet_upper.rds")

## synthetic
ctrl$sampling <- "smote"
rf_enet_smote <- train(
  qc19 ~ .,
  data = train_enet,
  method = "rf",
  trControl = ctrl
)
saveRDS(rf_enet_smote, file = "models/rf_enet_smote.rds")

```

### Gradient Boosting Machines (GBM)

```{r}
# enet

## under
ctrl$sampling <- "down"
gbm_enet_under <- train(
  qc19 ~ .,
  data = train_enet,
  method = "gbm",
  trControl = ctrl
)
saveRDS(gbm_enet_under, file = "models/gbm_enet_under.rds")

## upper
ctrl$sampling <- "up"
gbm_enet_upper <- train(
  qc19 ~ .,
  data = train_enet,
  method = "gbm",
  trControl = ctrl
)
saveRDS(gbm_enet_upper, file = "models/gbm_enet_upper.rds")

## synthetic
ctrl$sampling <- "smote"
gbm_enet_smote <- train(
  qc19 ~ .,
  data = train_enet,
  method = "gbm",
  trControl = ctrl
)
saveRDS(gbm_enet_smote, file = "models/gbm_enet_smote.rds")
```

### Support Vectoc Machine (SVM)

```{r}
# enet

## under
ctrl$sampling <- "down"
svm_enet_under <- train(
  qc19 ~ .,
  data = train_enet,
  method = "svmRadial",
  trControl = ctrl
)
saveRDS(svm_enet_under, file = "models/svm_enet_under.rds")

## upper
ctrl$sampling <- "up"
svm_enet_upper <- train(
  qc19 ~ .,
  data = train_enet,
  method = "svmRadial",
  trControl = ctrl
)
saveRDS(svm_enet_upper, file = "models/svm_enet_upper.rds")

## synthetic
ctrl$sampling <- "smote"
svm_enet_smote <- train(
  qc19 ~ .,
  data = train_enet,
  method = "svmRadial",
  trControl = ctrl
)
saveRDS(svm_enet_smote, file = "models/svm_enet_smote.rds")

```

# Performance Evaluation

## Performance Evaluation on Training Data

```{r}
rf_enet_under <- read_rds("models/rf_enet_under.rds")
rf_enet_over <- read_rds("models/rf_enet_upper.rds")

results_train <- resamples(list(rf_eu = rf_enet_under,
               rf_eo = rf_enet_over))  
summary(results_train)
```

```{r}
bwplot(results_train, scales = list(x = list(relation = "free"), y = list(relation = "free")))
```

## Prediction

### Individual Level

```{r}
test <- test %>% 
  mutate(qc19 = as.factor(qc19))

p_rf_eu <- predict(rf_enet_under, test) 
p_rf_eo <- predict(rf_enet_over, test)

confusionMatrix(p_rf_eu, test$qc19)$overall[1:2]
confusionMatrix(p_rf_eo, test$qc19)$overall[1:2]
```

### Country Level

```{r}
country_test <- test 
country_test$p_rf_eu <- p_rf_eu
country_test$p_rf_eo <- p_rf_eo

original <- country_test %>% 
  group_by(isocntry, qc19) %>%
  summarise(count = n()) %>% 
  group_by(isocntry) %>% 
  mutate(pcg = count/sum(count))

country_rfeu <- country_test %>% 
  group_by(isocntry, p_rf_eu) %>%
  summarise(count = n()) %>% 
  group_by(isocntry) %>% 
  mutate(pcg = count/sum(count))
country_rfeu

country_rfeo <- country_test %>% 
  group_by(isocntry, p_rf_eo) %>%
  summarise(count = n()) %>% 
  group_by(isocntry) %>% 
  mutate(pcg = count/sum(count))
country_rfeo

comparison <- cbind(select(original, c(isocntry,qc19, pcg)), country_rfeu$pcg, country_rfeo$pcg) %>% 
  rename("response" = 2,
         "original" = 3,
         "rfeu" = 4,
         "rfeo" = 5)
comparison
```
